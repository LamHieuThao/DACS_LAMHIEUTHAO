import os
import glob
import librosa
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, roc_curve, auc, classification_report
import joblib
import json

def extract_mfcc(audio_path, n_mfcc=13, n_fft=2048, hop_length=512):
    try:
        y, sr = librosa.load(audio_path, sr=None)
        if len(y) < n_fft:
            print(f"[SHORT] {audio_path} - too short ({len(y)} samples)")
            return None
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)
        return np.mean(mfcc.T, axis=0)
    except Exception as e:
        print(f"[ERROR] {audio_path}: {e}")
        return None

def load_dataset(path, label):
    features, labels = [], []
    files = glob.glob(os.path.join(path, "*.wav"))
    print(f"Loading from {path} - Found {len(files)} files")
    for f in files:
        mfcc = extract_mfcc(f)
        if mfcc is not None:
            features.append(mfcc)
            labels.append(label)
    return features, labels

def balance_data(X, y):
    X = np.array(X)
    y = np.array(y)
    class0 = X[y == 0]
    class1 = X[y == 1]

    if len(class0) > len(class1):
        class1 = resample(class1, replace=True, n_samples=len(class0), random_state=42)
    else:
        class0 = resample(class0, replace=True, n_samples=len(class1), random_state=42)

    X_balanced = np.vstack((class0, class1))
    y_balanced = np.array([0] * len(class0) + [1] * len(class1))

    return X_balanced, y_balanced

def v·∫Ω_roc(y_true, y_score, ti√™u_ƒë·ªÅ, t√™n_t·ªáp):
    fpr, tpr, _ = roc_curve(y_true, y_score)
    roc_auc = auc(fpr, tpr)

    plt.figure()
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')
    plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(ti√™u_ƒë·ªÅ)
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.savefig(t√™n_t·ªáp)
    plt.close()
    print(f"üíæ ƒê√£ l∆∞u {t√™n_t·ªáp}")

def v·∫Ω_roc_so_s√°nh(y_trains, y_probas, labels, title, filename):
    plt.figure()
    for y_true, y_score, label in zip(y_trains, y_probas, labels):
        fpr, tpr, _ = roc_curve(y_true, y_score)
        roc_auc = auc(fpr, tpr)
        plt.plot(fpr, tpr, lw=2, label=f'{label} (AUC = {roc_auc:.2f})')

    plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(title)
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.savefig(filename)
    plt.close()
    print(f"üíæ ƒê√£ l∆∞u {filename}")

def l∆∞u_b√°o_c√°o_th√†nh_·∫£nh(report_text, filename, title):
    fig, ax = plt.subplots(figsize=(8, 4))
    ax.axis('off')
    ax.text(0, 1, title + "\n\n" + report_text, fontsize=10, va='top', family='monospace')
    plt.tight_layout()
    plt.savefig(filename)
    plt.close()
    print(f"üñºÔ∏è ƒê√£ l∆∞u {filename}")

def train():
    real_dir = r"D:\DeepFake-Audio-Detection-MFCC-main\DeepFake-Audio-Detection-MFCC-main\real_audio"
    fake_dir = r"D:\DeepFake-Audio-Detection-MFCC-main\DeepFake-Audio-Detection-MFCC-main\deepfake_audio"

    X_real, y_real = load_dataset(real_dir, 0)
    X_fake, y_fake = load_dataset(fake_dir, 1)

    print(f"Loaded Real: {len(X_real)}, Fake: {len(X_fake)}")

    X, y = X_real + X_fake, y_real + y_fake

    # ‚ûï Test ch∆∞a c√¢n b·∫±ng
    X_orig_train, X_orig_test, y_orig_train, y_orig_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42)

    scaler_orig = StandardScaler()
    X_orig_train_scaled = scaler_orig.fit_transform(X_orig_train)
    X_orig_test_scaled = scaler_orig.transform(X_orig_test)

    joblib.dump(scaler_orig, "b·ªô_chu·∫©n_h√≥a_ch∆∞a_c√¢n_b·∫±ng.pkl")
    joblib.dump((X_orig_test_scaled, y_orig_test), "t·∫≠p_test_ch∆∞a_c√¢n_b·∫±ng.pkl")

    # ‚ûï C√¢n b·∫±ng d·ªØ li·ªáu
    X_bal, y_bal = balance_data(X, y)
    print(f"After balancing: Total = {len(X_bal)} samples")

    X_train, X_test, y_train, y_test = train_test_split(
        X_bal, y_bal, test_size=0.2, stratify=y_bal, random_state=42)

    print(f"Train: {len(X_train)} | Test: {len(X_test)}")

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = SVC(kernel='linear', probability=True, random_state=42)
    model.fit(X_train_scaled, y_train)

    # D·ª± ƒëo√°n
    y_train_pred = model.predict(X_train_scaled)
    y_train_proba = model.predict_proba(X_train_scaled)[:, 1]

    y_test_pred = model.predict(X_test_scaled)
    y_test_proba = model.predict_proba(X_test_scaled)[:, 1]

    y_orig_test_proba = model.predict_proba(X_orig_test_scaled)[:, 1]

    # ROC t·ª´ng t·∫≠p
    v·∫Ω_roc(y_train, y_train_proba, "ROC - T·∫≠p Hu·∫•n Luy·ªán", "roc_train.png")
    v·∫Ω_roc(y_test, y_test_proba, "ROC - T·∫≠p Test C√¢n B·∫±ng", "roc_test_balanced.png")
    v·∫Ω_roc(y_orig_test, y_orig_test_proba, "ROC - T·∫≠p Test Ch∆∞a C√¢n B·∫±ng", "roc_test_unbalanced.png")

    # So s√°nh ROC
    v·∫Ω_roc_so_s√°nh(
        [y_train, y_test, y_orig_test],
        [y_train_proba, y_test_proba, y_orig_test_proba],
        ["Train", "Test C√¢n B·∫±ng", "Test Ch∆∞a C√¢n B·∫±ng"],
        "So S√°nh ROC C√°c T·∫≠p",
        "roc_so_sanh.png"
    )

    v·∫Ω_roc_so_s√°nh(
        [y_test, y_orig_test],
        [y_test_proba, y_orig_test_proba],
        ["Test C√¢n B·∫±ng", "Test Ch∆∞a C√¢n B·∫±ng"],
        "So S√°nh ROC - Test C√¢n B·∫±ng vs Ch∆∞a C√¢n B·∫±ng",
        "roc_test_comparison_bal_vs_unbal.png"
    )

    # üìã B√°o c√°o ph√¢n lo·∫°i
    train_report = classification_report(y_train, y_train_pred, target_names=["Real", "Fake"])
    test_report = classification_report(y_test, y_test_pred, target_names=["Real", "Fake"])

    print("\nüìã B√°o C√°o - T·∫≠p Hu·∫•n Luy·ªán:")
    print(train_report)
    print("üìã B√°o C√°o - T·∫≠p Test C√¢n B·∫±ng:")
    print(test_report)

    # Ghi file text
    with open("b√°o_c√°o_ƒë√°nh_gi√°.txt", "w", encoding="utf-8") as f:
        f.write("üìã B√°o C√°o - T·∫≠p Hu·∫•n Luy·ªán:\n")
        f.write(train_report)
        f.write("\nüìã B√°o C√°o - T·∫≠p Test C√¢n B·∫±ng:\n")
        f.write(test_report)

    # V·∫Ω b√°o c√°o th√†nh ·∫£nh
    l∆∞u_b√°o_c√°o_th√†nh_·∫£nh(train_report, "b√°o_c√°o_train.png", "B√°o C√°o Hu·∫•n Luy·ªán")
    l∆∞u_b√°o_c√°o_th√†nh_·∫£nh(test_report, "b√°o_c√°o_test.png", "B√°o C√°o Test C√¢n B·∫±ng")

    # Ghi l·∫°i k·∫øt qu·∫£
    history = {
        "train_acc": accuracy_score(y_train, y_train_pred),
        "val_acc": accuracy_score(y_test, y_test_pred),
        "train_loss": 1 - accuracy_score(y_train, y_train_pred),
        "val_loss": 1 - accuracy_score(y_test, y_test_pred)
    }

    with open("l·ªãch_s·ª≠_hu·∫•n_luy·ªán.json", "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False)

    # L∆∞u m√¥ h√¨nh v√† d·ªØ li·ªáu
    joblib.dump(model, "m√¥_h√¨nh_svm.pkl")
    joblib.dump(scaler, "b·ªô_chu·∫©n_h√≥a.pkl")
    np.savez("t·∫≠p_test_c√¢n_b·∫±ng.npz", X_test=X_test_scaled, y_test=y_test)

    print("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t. ƒê√£ l∆∞u m√¥ h√¨nh, scaler, d·ªØ li·ªáu, bi·ªÉu ƒë·ªì v√† b√°o c√°o.")

if __name__ == "__main__":
    train()
