import os
import json
import numpy as np
import joblib
import matplotlib.pyplot as plt
from sklearn.metrics import (
    confusion_matrix, ConfusionMatrixDisplay,
    roc_auc_score, classification_report,
    roc_curve, auc
)

# ğŸ¨ Tá»± Ä‘á»™ng chá»n mÃ u chá»¯ phÃ¹ há»£p vá»›i mÃ u ná»n
def get_text_color(cell_value, max_value, threshold=0.4):
    # Náº¿u giÃ¡ trá»‹ lá»›n thÃ¬ chá»¯ tráº¯ng, nhá» thÃ¬ chá»¯ Ä‘en
    return 'white' if cell_value > max_value * threshold else 'black'

# ğŸ“Š HÃ m váº½ ma tráº­n nháº§m láº«n
def draw_confusion_matrix(cm, title, filename, color_map='Blues', save=False):
    fig, ax = plt.subplots(figsize=(5, 5))
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Real", "Fake"])
    disp.plot(cmap=color_map, ax=ax, colorbar=False)
    plt.title(title)
    plt.grid(False)

    # Hiá»ƒn thá»‹ sá»‘ liá»‡u rÃµ rÃ ng
    max_val = cm.max()
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            color = get_text_color(cm[i, j], max_val)
            ax.text(j, i, str(cm[i, j]), ha='center', va='center', fontsize=12, color=color)

    if save:
        plt.savefig(filename)
        print(f"ğŸ’¾ ÄÃ£ lÆ°u {filename}")
    plt.show()

# ğŸ“ˆ Váº½ biá»ƒu Ä‘á»“ Ä‘á»™ chÃ­nh xÃ¡c vÃ  Ä‘á»™ lá»—i tá»« file JSON
def plot_history(save=False):
    try:
        with open("lá»‹ch_sá»­_huáº¥n_luyá»‡n.json", "r", encoding="utf-8") as f:
            history = json.load(f)
    except FileNotFoundError:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file 'lá»‹ch_sá»­_huáº¥n_luyá»‡n.json'")
        return

    acc = [history["train_acc"], history["val_acc"]]
    loss = [history["train_loss"], history["val_loss"]]
    labels = ["Huáº¥n luyá»‡n", "Kiá»ƒm tra"]

    plt.figure(figsize=(12, 5))

    # Accuracy
    plt.subplot(1, 2, 1)
    bars = plt.bar(labels, acc, color=['mediumseagreen', 'darkorange'])
    plt.title("Accuracy")
    plt.ylim(0, 1)
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f"{yval:.2f}", ha='center', fontsize=12)
    plt.ylabel("Tá»‰ lá»‡ chÃ­nh xÃ¡c")

    # Loss
    plt.subplot(1, 2, 2)
    bars = plt.bar(labels, loss, color=['skyblue', 'tomato'])
    plt.title("Loss")
    plt.ylim(0, 1)
    for bar in bars:
        yval = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, f"{yval:.2f}", ha='center', fontsize=12)
    plt.ylabel("Äá»™ lá»—i")

    plt.suptitle("Hiá»‡u suáº¥t mÃ´ hÃ¬nh", fontsize=16)
    plt.tight_layout()
    if save:
        plt.savefig("biá»ƒu_Ä‘á»“_Ä‘á»™_chÃ­nh_xÃ¡c_Ä‘á»™_lá»—i.png")
        print("ğŸ’¾ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ Accuracy/Loss")
    plt.show()

# ğŸ§ª Váº½ biá»ƒu Ä‘á»“ ROC
def plot_roc_curve(y_true, y_proba, title, filename):
    fpr, tpr, _ = roc_curve(y_true, y_proba)
    roc_auc = auc(fpr, tpr)

    plt.figure(figsize=(6, 6))
    plt.plot(fpr, tpr, color='crimson', lw=2, label=f"AUC = {roc_auc:.2f}")
    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(title)
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(filename)
    print(f"ğŸ’¾ ÄÃ£ lÆ°u biá»ƒu Ä‘á»“ ROC: '{filename}'")
    plt.show()

# âœ… ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test Ä‘Ã£ cÃ¢n báº±ng
def evaluate_test_set(save=False):
    try:
        data = np.load("táº­p_test_cÃ¢n_báº±ng.npz")
        X_test, y_test = data["X_test"], data["y_test"]
        model = joblib.load("mÃ´_hÃ¬nh_svm.pkl")
    except Exception as e:
        print(f"âŒ Lá»—i khi load dá»¯ liá»‡u hoáº·c mÃ´ hÃ¬nh: {e}")
        return

    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    cm = confusion_matrix(y_test, y_pred)
    draw_confusion_matrix(cm, "Ma tráº­n nháº§m láº«n (CÃ¢n báº±ng)", "ma_tráº­n_nháº§m_láº«n_cÃ¢n_báº±ng.png", "Blues", save)

    print("ğŸ“„ BÃ¡o cÃ¡o phÃ¢n loáº¡i (CÃ¢n báº±ng):")
    print(classification_report(y_test, y_pred, target_names=["Real", "Fake"]))
    auc_score = roc_auc_score(y_test, y_proba)
    print(f"ğŸ” AUC Score (CÃ¢n báº±ng): {auc_score:.4f}")

    if save:
        plot_roc_curve(y_test, y_proba, "ROC - Dá»¯ liá»‡u Ä‘Ã£ cÃ¢n báº±ng", "biá»ƒu_Ä‘á»“_ROC_cÃ¢n_báº±ng.png")

# âš–ï¸ ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh trÃªn táº­p test chÆ°a cÃ¢n báº±ng
def evaluate_unbalanced_test_set(save=False):
    try:
        model = joblib.load("mÃ´_hÃ¬nh_svm.pkl")
        X_test, y_test = joblib.load("táº­p_test_chÆ°a_cÃ¢n_báº±ng.pkl")
    except Exception as e:
        print(f"âŒ Lá»—i khi load dá»¯ liá»‡u chÆ°a cÃ¢n báº±ng: {e}")
        return

    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    cm = confusion_matrix(y_test, y_pred)
    draw_confusion_matrix(cm, "Ma tráº­n nháº§m láº«n (ChÆ°a cÃ¢n báº±ng)", "ma_tráº­n_nháº§m_láº«n_chÆ°a_cÃ¢n_báº±ng.png", "Oranges", save)

    print("ğŸ“„ BÃ¡o cÃ¡o phÃ¢n loáº¡i (ChÆ°a cÃ¢n báº±ng):")
    print(classification_report(y_test, y_pred, target_names=["Real", "Fake"]))
    auc_score = roc_auc_score(y_test, y_proba)
    print(f"ğŸ” AUC Score (ChÆ°a cÃ¢n báº±ng): {auc_score:.4f}")

    if save:
        plot_roc_curve(y_test, y_proba, "ROC - Dá»¯ liá»‡u chÆ°a cÃ¢n báº±ng", "biá»ƒu_Ä‘á»“_ROC_chÆ°a_cÃ¢n_báº±ng.png")

# ğŸš€ Cháº¡y toÃ n bá»™
if __name__ == "__main__":
    plot_history(save=True)
    evaluate_test_set(save=True)
    evaluate_unbalanced_test_set(save=True)
